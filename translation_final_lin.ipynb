{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitdca29ddb9db04064946b0c1f07a104d6",
   "display_name": "Python 3.7.9 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "1bf5cdd3e3c5387cc6e4c57baa0cd096b58cddb518bc7223d815477569d910d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Project for Machine Learning\n",
    "- Key words: `NMT`, `Transformer`, `PyTorch`, `Multi30k`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torchtext\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.optim.lr_scheduler import StepLR,LambdaLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from my_transformer_lin import *\n",
    "\n",
    "% matplotlib inline\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "source": [
    "## Data Prerocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pth_base = \"./.data/multi30k/task1/raw/\"\n",
    "train_pths = ('train.de', 'train.en')\n",
    "val_pths = ('val.de', 'val.en')\n",
    "test_pths = ('test_2016_flickr.de', 'test_2016_flickr.en')\n",
    "\n",
    "train_filepaths = [(pth_base + pth) for pth in train_pths]\n",
    "val_filepaths = [(pth_base + pth) for pth in val_pths]\n",
    "test_filepaths = [(pth_base + pth) for pth in test_pths]\n",
    "\n",
    "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "\n",
    "de_vocab = build_vocab(train_filepaths[0], de_tokenizer, min_freq=3)\n",
    "en_vocab = build_vocab(train_filepaths[1], en_tokenizer, min_freq=3)\n",
    "\n",
    "train_data = data_process(train_filepaths, de_vocab, en_vocab, de_tokenizer, en_tokenizer)\n",
    "val_data = data_process(val_filepaths, de_vocab, en_vocab, de_tokenizer, en_tokenizer)\n",
    "test_data = data_process(test_filepaths, de_vocab, en_vocab, de_tokenizer, en_tokenizer)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\ntrain size: 29000\nval size: 1014\ntest size: 1000\nde vocab size: 5374\nen vocab size: 4555\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "print(\"train size:\", len(train_data))\n",
    "print(\"val size:\", len(val_data))\n",
    "print(\"test size:\", len(test_data))\n",
    "print(\"de vocab size:\", len(de_vocab))\n",
    "print(\"en vocab size:\", len(en_vocab))"
   ]
  },
  {
   "source": [
    "## Hyper-parameters Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_VOCAB_SIZE = len(de_vocab)\n",
    "TGT_VOCAB_SIZE = len(en_vocab)\n",
    "BATCH_SIZE = 128\n",
    "NUM_ENCODER_LAYERS = 3 # no help, 3 is better\n",
    "NUM_DECODER_LAYERS = 3 # no help, 3 is better\n",
    "EMB_SIZE = 256\n",
    "FFN_HID_DIM = 512\n",
    "NHEAD = 8 # no help, hard converge\n",
    "DROPOUT = 0.1\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "# LR_STEP = 30\n",
    "# warmup_steps = 4000\n",
    "model_name = \"./models/transformer-6-3-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = de_vocab['<pad>']\n",
    "BOS_IDX = de_vocab['<bos>']\n",
    "EOS_IDX = de_vocab['<eos>']\n",
    "\n",
    "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=get_collate_fn(PAD_IDX,BOS_IDX,EOS_IDX))\n",
    "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=get_collate_fn(PAD_IDX,BOS_IDX,EOS_IDX))\n",
    "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True, collate_fn=get_collate_fn(PAD_IDX,BOS_IDX,EOS_IDX))"
   ]
  },
  {
   "source": [
    "## Model Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MyTf(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, \n",
    "                   EMB_SIZE, NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, PAD_IDX,\n",
    "                   FFN_HID_DIM, DROPOUT)\n",
    "\n",
    "transformer = transformer.to(device)\n",
    "\n",
    "# lrate = lambda step_num: EMB_SIZE**-0.5 * np.minimum(step_num**-0.5,step_num*warmup_steps**-1.5)\n",
    "\n",
    "# scheduler = StepLR(optimizer, step_size=LR_STEP, gamma=0.1)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model has 7,667,147 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(transformer):,} trainable parameters')"
   ]
  },
  {
   "source": [
    "## Train and Evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_curve = []\n",
    "val_loss_curve = []\n",
    "min_val_loss = 999\n",
    "steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (torch.triu(torch.ones((1, 1))) == 1).transpose(0, 1)\n",
    "torch.save(transformer, model_name+\"-best.pth.tar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1, Train loss: 4.021, Val loss: 3.568, Epoch time = 687.916s\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-cce130620096>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\BaiyueWang\\Desktop\\machine learning 2021\\project\\nmt\\nmt-multi30k-pytorch\\utils.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_iter, optimizer, loss_fn, device)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\Python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\Python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(transformer, train_iter, optimizer, loss_fn, device)\n",
    "    end_time = time.time()\n",
    "    val_loss = evaluate(transformer, valid_iter, loss_fn, device)\n",
    "#     scheduler.step()\n",
    "    \n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        transformer.eval()\n",
    "        torch.save(transformer, model_name+\"-best.pth.tar\")\n",
    "        \n",
    "    if epoch % 30 == 0:\n",
    "        transformer.eval()\n",
    "        torch.save(transformer, model_name+\"-ckpt-\"+str(epoch)+\".pth.tar\")\n",
    "        \n",
    "    train_loss_curve.append(train_loss)\n",
    "    val_loss_curve.append(val_loss)\n",
    "\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"min val loss:\",min_val_loss)\n",
    "plt.plot(train_loss_curve)\n",
    "plt.plot(val_loss_curve)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend((\"train loss\",\"val loss\"))\n",
    "plt.savefig(\"./images/\" + model_name.split(sep=\"/\")[-1] + \".png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(transformer, \"eine gruppe von menschen steht vor einem iglu .\", de_vocab, en_vocab,de_tokenizer, BOS_IDX, EOS_IDX, device)"
   ]
  },
  {
   "source": [
    "## Save the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.eval()\n",
    "torch.save(transformer, model_name + \".pth.tar\")"
   ]
  },
  {
   "source": [
    "## Calculate the BLEU Score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load reference'''\n",
    "with open(test_filepaths[0], 'r', encoding='utf8') as f:\n",
    "    test_data_ = f.readlines()\n",
    "    \n",
    "'''make predictions'''\n",
    "predictions = []\n",
    "for data in test_data_:\n",
    "    temp_trans = translate(transformer, data.lower(), de_vocab, en_vocab, de_tokenizer, BOS_IDX, EOS_IDX, device)\n",
    "    predictions.append(temp_trans[1:-3]+\" . \\n\")\n",
    "\n",
    "'''update predictions.txt'''\n",
    "with open(\"predictions.txt\",'w+') as f:\n",
    "    f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''eliminate <unk>''' \n",
    "# for i,pre in enumerate(predictions):\n",
    "#     predictions[i] = pre.replace(\"<unk>\",\" \")\n",
    "# '''update predictions.txt'''\n",
    "# with open(\"predictions.txt\",'w+') as f:\n",
    "#     f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! perl ./multi-bleu.perl -lc reference.txt < predictions.txt\n",
    "\n",
    "with open(model_name + \".txt\",'w+') as f:    \n",
    "    f.writelines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "references_corpus  = []\n",
    "candidate_corpus = []\n",
    "'''update reference.txt'''\n",
    "'''update reference.txt'''\n",
    "with open(test_filepaths[1], 'r', encoding='utf8') as f:\n",
    "    reference = f.readlines()\n",
    "\n",
    "for i in range(len(reference)):\n",
    "    reference[i] = \" \".join(en_tokenizer(reference[i])).lower()\n",
    "\n",
    "for pred,ref in zip(predictions, reference):\n",
    "    temp = pred.rstrip(\" \\n\").split(\" \")\n",
    "    candidate_corpus.append(temp)\n",
    "    temp = ref.rstrip(\" \\n\").split(\" \")\n",
    "    references_corpus.append([temp])\n",
    "bleu_torchtext = bleu_score(candidate_corpus, references_corpus)\n",
    "print(f'BLEU score = {bleu_torchtext*100:.2f}')"
   ]
  }
 ]
}